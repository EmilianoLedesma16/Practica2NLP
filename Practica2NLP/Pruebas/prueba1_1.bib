@misc{li2025dancingcritiquesenhancingllm,
  title={Dancing with Critiques: Enhancing LLM Reasoning with Stepwise Natural Language Self-Critique},
  author={Yansi Li and Jiahao Xu and Tian Liang and Xingyu Chen and Zhiwei He and Qiuzhi Liu and Rui Wang and Zhuosheng Zhang and Zhaopeng Tu and Haitao Mi and Dong Yu},
  year={2025},
  eprint={2503.17363},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  doi={https://doi.org/10.13140/RG.2.2.27912.33289},
  url={https://arxiv.org/abs/2503.17363},
  abstract={Improving the reasoning capabilities of large language models (LLMs), 
  especially in complex tasks requiring multi-step logical deductions, remains 
  a significant challenge. Traditional inference-time scaling methods use scalar 
  reward signals from reward models to evaluate candidate reasoning steps; 
  however, these scalar rewards lack the nuanced qualitative information 
  essential for understanding and justifying each step. In this paper, we 
  propose a novel inference-time scaling approach: Stepwise Natural Language 
  Self-Critique (PANEL), which leverages model-generated self-critiques as 
  feedback to guide step-level search. By generating rich, human-comprehensible 
  critiques for each candidate reasoning step, PANEL retains essential qualitative 
  information, facilitating more informed decision-making during inference. 
  This approach circumvents the need for task-specific verifiers and associated 
  training overhead, making it broadly applicable across various tasks. 
  Experimental results on challenging reasoning benchmarks, including AIME and GPQA, 
  demonstrate that PANEL significantly enhances reasoning performance, outperforming 
  traditional scalar reward-based methods. Our code is available at 
  this https URL to support and encourage further 
  research in this promising field.}
}
